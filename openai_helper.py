import os
import json
from openai import OpenAI
import logging

# Initialize OpenAI client
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

def generate_structured_brief(raw_input, service_type):
    """
    Convert raw marketing requirements into structured brief format using GPT-4o-mini
    """
    
    # Service type mapping for context
    service_context = {
        'meta_ads': 'Metaå»£å‘ŠæŠ•æ”¾ (Facebook & Instagram)',
        'google_ads': 'Google Ads å»£å‘ŠæŠ•æ”¾',
        'seo': 'é›»å•† SEO æœå°‹å¼•æ“å„ªåŒ–'
    }
    
    service_name = service_context.get(service_type, service_type)
    
    prompt = f"""
è«‹å°‡ä»¥ä¸‹è¡ŒéŠ·éœ€æ±‚è½‰æ›ç‚ºçµæ§‹åŒ–çš„å°ˆæ¡ˆç°¡ä»‹æ ¼å¼ï¼Œé‡å°{service_name}æœå‹™ï¼š

åŸå§‹éœ€æ±‚ï¼š
{raw_input}

è«‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¼¸å‡ºçµæ§‹åŒ–ç°¡ä»‹ï¼š

ğŸ“Œã€å°ˆæ¡ˆæ¦‚è¦ã€‘
ç°¡çŸ­æ•˜è¿°æ­¤å°ˆæ¡ˆçš„ç›®çš„èˆ‡èƒŒæ™¯

ğŸ“Œã€ç›®æ¨™æ—ç¾¤ã€‘
æ˜ç¢ºæŒ‡å‡ºå—çœ¾å°è±¡ï¼ˆå¹´é½¡ã€æ€§åˆ¥ã€ç”Ÿæ´»é¢¨æ ¼æˆ–è³¼ç‰©ç¿’æ…£ï¼‰

ğŸ“Œã€éœ€æ±‚é …ç›®ã€‘
åˆ—å‡ºæœ¬æ¬¡å¸Œæœ›ä¹™æ–¹åŸ·è¡Œçš„å…·é«”è¡ŒéŠ·é …ç›®ï¼Œä¾‹å¦‚ï¼š
- é …ç›®1
- é …ç›®2
- é …ç›®3

ğŸ“Œã€é ç®—èˆ‡æ™‚ç¨‹ã€‘
- é ç®—ç¯„åœï¼šæ ¹æ“šåŸå§‹éœ€æ±‚æ¨ä¼°æˆ–æ¨™è¨»"å¾…è¨è«–"
- é–‹å§‹æ—¥æœŸï¼šYYYY/MM/DD æˆ– "å¾…ç¢ºèª"
- æ˜¯å¦å¯åˆ†æœŸï¼éˆæ´»èª¿æ•´ï¼šæ˜¯ï¼å¦

ğŸ“Œã€å°ˆæ¡ˆç›®æ¨™ã€‘
æœ¬æ¬¡è¡ŒéŠ·æ´»å‹•å¸Œæœ›é”æˆçš„å•†æ¥­æŒ‡æ¨™æˆ–é æœŸæˆæœ

ğŸ“Œã€åŸ·è¡Œé…åˆäº‹é …ã€‘
- ç´ ææä¾›ï¼šéœ€è¦é€²ä¸€æ­¥ç¢ºèª
- æ–‡æ¡ˆæ’°å¯«ï¼šéœ€è¦é€²ä¸€æ­¥ç¢ºèª  
- æºé€šé »ç‡ï¼šéœ€è¦é€²ä¸€æ­¥ç¢ºèª

ğŸ“Œã€å…¶ä»–èªªæ˜æˆ–é™åˆ¶æ¢ä»¶ã€‘
æ ¹æ“šåŸå§‹éœ€æ±‚æåŠçš„ç‰¹æ®Šè¦æ±‚æˆ–é™åˆ¶

ğŸ“Œã€å¯æä¾›ä¹‹è³‡æºã€‘
æ ¹æ“šåŸå§‹éœ€æ±‚æ¨ä¼°å¯èƒ½æœ‰çš„è³‡æº

ğŸ“Œã€ä¹™æ–¹éœ€ç‰¹åˆ¥å…·å‚™ã€‘
æ ¹æ“š{service_name}å’ŒåŸå§‹éœ€æ±‚ï¼Œåˆ—å‡ºå°ˆæ¥­è¦æ±‚

ğŸ“Œã€è£œå……èªªæ˜ã€‘
å…¶ä»–é‡è¦è³‡è¨Šæˆ–èƒŒæ™¯

è«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œå…§å®¹è¦å°ˆæ¥­ä¸”å…·é«”ã€‚å¦‚æœåŸå§‹éœ€æ±‚ä¸­æŸäº›è³‡è¨Šä¸è¶³ï¼Œè«‹åˆç†æ¨ä¼°æˆ–æ¨™è¨»"å¾…ç¢ºèª"ã€‚
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # Using gpt-4o-mini as requested
            messages=[
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è¡ŒéŠ·å°ˆæ¡ˆç¶“ç†ï¼Œæ“…é•·å°‡å®¢æˆ¶éœ€æ±‚è½‰æ›ç‚ºçµæ§‹åŒ–çš„å°ˆæ¡ˆç°¡ä»‹ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œå…§å®¹è¦å°ˆæ¥­ã€å…·é«”ä¸”å¯¦ç”¨ã€‚"
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            max_tokens=1500,
            temperature=0.7
        )
        
        structured_brief = response.choices[0].message.content.strip()
        return structured_brief
        
    except Exception as e:
        logging.error(f"OpenAI API error: {e}")
        return f"æŠ±æ­‰ï¼Œç„¡æ³•ç”Ÿæˆçµæ§‹åŒ–ç°¡ä»‹ã€‚éŒ¯èª¤ï¼š{str(e)}"

def generate_followup_questions(structured_brief):
    """
    Generate the three follow-up questions based on the structured brief
    """
    questions = {
        'materials': {
            'question': 'ğŸŸ§ è£œå• 1ï¼šç´ æç”±èª°æä¾›ï¼Ÿ\nè¡ŒéŠ·ç´ æï¼ˆåœ–ç‰‡ / å½±ç‰‡ï¼‰ç”±èª°æä¾›ï¼Ÿ',
            'options': [
                'æˆ‘æ–¹å·²æœ‰ç´ æ',
                'å¸Œæœ›ä¹™æ–¹æä¾›', 
                'é›™æ–¹å”ä½œè£½ä½œ'
            ]
        },
        'copywriting': {
            'question': 'ğŸŸ§ è£œå• 2ï¼šæ–‡æ¡ˆç”±èª°æ’°å¯«ï¼Ÿ\næœ¬æ¬¡è¡ŒéŠ·æ‰€éœ€æ–‡æ¡ˆï¼ˆå¦‚è²¼æ–‡ã€å»£å‘Šæ¨™é¡Œã€EDMï¼‰ç”±èª°æ’°å¯«ï¼Ÿ',
            'options': [
                'æˆ‘æ–¹æœƒæä¾›',
                'å¸Œæœ›ä¹™æ–¹æ’°å¯«',
                'é›™æ–¹å”ä½œç”¢å‡º'
            ]
        },
        'communication': {
            'question': 'ğŸŸ§ è£œå• 3ï¼šæºé€šèˆ‡é–‹æœƒé »ç‡ï¼Ÿ\né›™æ–¹é æœŸçš„å°æ¥é »ç‡ç‚ºä½•ï¼Ÿ',
            'options': [
                'æ¯é€±ä¸€æ¬¡æœƒè­°',
                'æ¯æœˆä¸€æ¬¡',
                'é—œéµç¯€é»å°æ¥å³å¯',
                'ä¸éœ€æœƒè­°ï¼Œåƒ…éœ€éåŒæ­¥è¯ç¹«'
            ]
        }
    }
    
    return questions